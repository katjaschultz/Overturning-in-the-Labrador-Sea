{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdd6d02-acc4-4de8-80e4-d50977e48dbc",
   "metadata": {},
   "source": [
    "# Load Argo data\n",
    "This notebook loads Argo Data from the Labrador Sea in between a specified time frame as an xarray dataset and saves it as an nc-file. The data loaded contains profiles of absolute salinity (SA), conservative temperatur (CT) and potential vorticity (PV) as a function of pressure sorted by depth levels and profile number. First the dataset for the whole period (2002-2023) is created, secondly a subset with different end and start dates is created. This subset uses the time span used in Holte & Straneo (2017) and was used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0189b7a7-648b-4fa4-97f7-1c6560ab6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# install argopy libary from github\n",
    "!pip install git+https://github.com/euroargodev/argopy.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8bb47fb-aea4-4ead-935f-bdd865a31e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2017\n"
     ]
    },
    {
     "ename": "FSTimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\fsspec\\asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[1;34m(event, coro, result, timeout)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\fsspec\\implementations\\http.py:227\u001b[0m, in \u001b[0;36mHTTPFileSystem._cat_file\u001b[1;34m(self, url, start, end, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_url(url), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m--> 227\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m r\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_not_found_for_status(r, url)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py:1101\u001b[0m, in \u001b[0;36mClientResponse.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traces:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\aiohttp\\streams.py:373\u001b[0m, in \u001b[0;36mStreamReader.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadany()\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\aiohttp\\streams.py:395\u001b[0m, in \u001b[0;36mStreamReader.readany\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadany\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_nowait(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\aiohttp\\streams.py:301\u001b[0m, in \u001b[0;36mStreamReader._wait\u001b[1;34m(self, func_name)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timer:\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\aiohttp\\helpers.py:735\u001b[0m, in \u001b[0;36mTimerContext.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cancelled:\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFSTimeoutError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m fetcher \u001b[38;5;241m=\u001b[39m ArgoDataFetcher(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearch\u001b[39m\u001b[38;5;124m'\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(year)\n\u001b[1;32m---> 39\u001b[0m ds_year \u001b[38;5;241m=\u001b[39m fetcher\u001b[38;5;241m.\u001b[39mregion([Lon0, Lon1, Lat0, Lat1, \u001b[38;5;241m0\u001b[39m, max_depth, year_start, year_end])\u001b[38;5;241m.\u001b[39mto_xarray()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Sort data into profiles, select variables and concatenate the current year's data to the main dataset\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\argopy\\fetchers.py:616\u001b[0m, in \u001b[0;36mArgoDataFetcher.to_xarray\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetcher:\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidFetcher(\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Initialize an access point (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFetchers\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    615\u001b[0m     )\n\u001b[1;32m--> 616\u001b[0m xds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetcher\u001b[38;5;241m.\u001b[39mto_xarray(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    617\u001b[0m xds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(xds)\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xds\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\argopy\\data_fetchers\\erddap_data.py:734\u001b[0m, in \u001b[0;36mErddapArgoDataFetcher.to_xarray\u001b[1;34m(self, errors, add_dm, concat, max_workers)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(URI) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    733\u001b[0m         \u001b[38;5;66;03m# log_argopy_callerstack()\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mopen_dataset(URI[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    735\u001b[0m         results \u001b[38;5;241m=\u001b[39m pre_process(results, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_opts)\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ClientResponseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\argopy\\stores\\filesystems.py:802\u001b[0m, in \u001b[0;36mhttpstore.open_dataset\u001b[1;34m(self, url, errors, **kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdwn_opts\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    801\u001b[0m     dwn_opts\u001b[38;5;241m.\u001b[39mupdate(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdwn_opts\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 802\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_url(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdwn_opts)\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\argopy\\stores\\filesystems.py:751\u001b[0m, in \u001b[0;36mhttpstore.download_url\u001b[1;34m(self, url, max_attempt, cat_opts, errors)\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, n_attempt\n\u001b[0;32m    750\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurateurl(url)\n\u001b[1;32m--> 751\u001b[0m data, n \u001b[38;5;241m=\u001b[39m make_request(\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs,\n\u001b[0;32m    753\u001b[0m     url,\n\u001b[0;32m    754\u001b[0m     max_attempt\u001b[38;5;241m=\u001b[39mmax_attempt,\n\u001b[0;32m    755\u001b[0m     cat_opts\u001b[38;5;241m=\u001b[39mcat_opts,\n\u001b[0;32m    756\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    757\u001b[0m )\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\argopy\\stores\\filesystems.py:737\u001b[0m, in \u001b[0;36mhttpstore.download_url.<locals>.make_request\u001b[1;34m(ffs, url, n_attempt, max_attempt, cat_opts, errors)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mFSTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    739\u001b[0m         log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\argopy\\stores\\filesystems.py:703\u001b[0m, in \u001b[0;36mhttpstore.download_url.<locals>.make_request\u001b[1;34m(ffs, url, n_attempt, max_attempt, cat_opts, errors)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_attempt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_attempt:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m         data \u001b[38;5;241m=\u001b[39m ffs\u001b[38;5;241m.\u001b[39mcat_file(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcat_opts)\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\fsspec\\asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\fsspec\\asyn.py:101\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m return_result \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# suppress asyncio.TimeoutError, raise FSTimeoutError\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n",
      "\u001b[1;31mFSTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#--------------- import libaries ---------------------------------------------\n",
    "import xarray as xr\n",
    "import argopy\n",
    "argopy.set_options(mode='research') # to only allow for qualitifly high data\n",
    "from argopy import DataFetcher as ArgoDataFetcher\n",
    "\n",
    "\n",
    "#--------------- SET VARIABLES -----------------------------------------------\n",
    "# Set time range\n",
    "start_year = 2002\n",
    "end_year   = 2023\n",
    "\n",
    "# Coordinates of Labrador Sea \n",
    "Lon0 = -66\n",
    "Lon1 = -44\n",
    "Lat0 = 45\n",
    "Lat1 = 68\n",
    "# maximum water depth\n",
    "max_depth = 2000\n",
    "\n",
    "# set file name\n",
    "filename = 'LabSea_Argo_2002_2023.nc'\n",
    "datapath = '.\\\\data\\\\'\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Create an empty xarray dataset to store the data\n",
    "ag = None\n",
    "\n",
    "# Loop through each year\n",
    "for year in range(start_year, end_year+1):\n",
    "\n",
    "    # Set the time range for the current year\n",
    "    year_start = f'{year}-01-01'\n",
    "    year_end = f'{year}-12-31'\n",
    "\n",
    "    # Load Argo data for the current year and region\n",
    "    fetcher = ArgoDataFetcher(mode='research', timeout=100000)\n",
    "    print(year)\n",
    "    ds_year = fetcher.region([Lon0, Lon1, Lat0, Lat1, 0, max_depth, year_start, year_end]).to_xarray()\n",
    "    \n",
    "    # Sort data into profiles, select variables and concatenate the current year's data to the main dataset\n",
    "    if ag is None:\n",
    "        ag = ds_year.argo.point2profile()\n",
    "        ag.argo.teos10(['SA', 'CT', 'PV'])\n",
    "    else:\n",
    "        ag_points = ds_year.argo.point2profile()\n",
    "        ag_points.argo.teos10(['SA', 'CT', 'PV'])\n",
    "        ag = xr.concat([ag, ag_points], dim='N_PROF')\n",
    "\n",
    "# Print the final dataset to check variables\n",
    "print(ag)\n",
    "\n",
    "#save dataset as netcdf file\n",
    "ag.to_netcdf(datapath + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8162166-1397-41b0-a905-cef497905884",
   "metadata": {},
   "source": [
    "# Subdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fae891-6876-45f4-9b8e-30864a3765a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- SET VARIABLES -----------------------------------------------\n",
    "# Set time range\n",
    "# set time to only load dataset for reproducing Holte & Straneo (2017) \n",
    "# timespan set to '2002-03-01' to '2016-04-30' below\n",
    "start_year = 2002\n",
    "end_year   = 2016\n",
    "\n",
    "# Coordinates of Labrador Sea \n",
    "Lon0 = -66\n",
    "Lon1 = -44\n",
    "Lat0 = 45\n",
    "Lat1 = 68\n",
    "# maximum water depth\n",
    "max_depth = 2000\n",
    "\n",
    "# set file name\n",
    "filename2 = 'LabSea_Argo_2002_2016.nc'\n",
    "datapath = '.\\\\data\\\\'\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Create an empty array\n",
    "ag2 = None\n",
    "\n",
    "for year in range(start_year2, end_year2+1):\n",
    "\n",
    "    # Set the time range for the current year\n",
    "    if (start_year2 < year < end_year2):\n",
    "        year_start = f'{year}-01-01'\n",
    "        year_end = f'{year}-12-31'\n",
    "    elif year == 2002:\n",
    "        year_start = f'{year}-03-01' # time span for reproducing Holte & Straneo (2017) data\n",
    "        year_end = f'{year}-12-31'\n",
    "    elif year == 2016:\n",
    "        year_start = f'{year}-01-01'\n",
    "        year_end = f'{year}-04-30' # time span for reproducing Holte & Straneo (2017) data\n",
    "\n",
    "    # Load Argo data for the current year and region\n",
    "    fetcher = ArgoDataFetcher(mode='research', timeout=100000)\n",
    "    print(year)\n",
    "    ds_year = fetcher.region([Lon0, Lon1, Lat0, Lat1, 0, max_depth, year_start, year_end]).to_xarray()\n",
    "    \n",
    "    # Sort data into profiles, select variables and concatenate the current year's data to the main dataset\n",
    "    if ag2 is None:\n",
    "        ag2 = ds_year.argo.point2profile()\n",
    "        ag2.argo.teos10(['SA', 'CT', 'PV'])\n",
    "    else:\n",
    "        ag_points = ds_year.argo.point2profile()\n",
    "        ag_points.argo.teos10(['SA', 'CT', 'PV'])\n",
    "        ag2 = xr.concat([ag2, ag_points], dim='N_PROF')\n",
    "\n",
    "# Print the final dataset to check variables\n",
    "print(ag2)\n",
    "\n",
    "#save dataset as netcdf file\n",
    "ag2.to_netcdf(datapath + filename2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
